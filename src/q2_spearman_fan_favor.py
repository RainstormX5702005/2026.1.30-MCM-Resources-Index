import numpy as np
import pandas as pd
from scipy.stats import spearmanr
from typing import Tuple, Dict

from configs.config import OUTPUT_DIR

# é…ç½®è¾“å…¥æ–‡ä»¶è·¯å¾„
INPUT_FILE = OUTPUT_DIR / "question2_res" / "wilcoxon" / "wilcoxon_full_data.csv"


def load_and_validate_data(file_path: str) -> pd.DataFrame:
    """
    åŠ è½½æ•°æ®å¹¶è¿›è¡ŒåŸºç¡€æ ¡éªŒ
    """
    print(f"Loading data from {file_path}...")
    try:
        df = pd.read_csv(file_path)
    except FileNotFoundError:
        raise FileNotFoundError(f"é”™è¯¯: æ‰¾ä¸åˆ°æ–‡ä»¶ {file_path}ã€‚è¯·ç¡®è®¤æ–‡ä»¶è·¯å¾„æ­£ç¡®ã€‚")

    # å¿…è¦çš„åˆ—æ£€æŸ¥
    required_columns = ["season", "week", "method1_pos", "method2_pos", "judge_score"]
    missing = [c for c in required_columns if c not in df.columns]
    if missing:
        raise ValueError(f"æ•°æ®é”™è¯¯: ç¼ºå°‘å…³é”®åˆ— {missing}ã€‚è¯·æ£€æŸ¥ CSV æ–‡ä»¶å¤´ã€‚")

    # ç±»å‹è½¬æ¢ä¸æ¸…æ´—
    for col in required_columns:
        df[col] = pd.to_numeric(df[col], errors="coerce")

    # åˆ é™¤å«æœ‰ç©ºå€¼çš„è¡Œ
    initial_len = len(df)
    df = df.dropna(subset=required_columns).copy()
    print(f"Data loaded. Rows: {len(df)} (Dropped {initial_len - len(df)} NaN rows)")

    return df


def calculate_correlation_with_judges(
    df: pd.DataFrame,
    method_col: str,
    judge_col: str = "judge_score",
    min_contestants: int = 4,
) -> pd.DataFrame:
    """
    è®¡ç®—æ¯ç§æ–¹æ³•ä¸è¯„å§”åˆ†æ•°çš„ Spearman ç›¸å…³ç³»æ•°

    æ ¸å¿ƒé€»è¾‘ï¼š
    - å¦‚æœ method ä¸ judge_score é«˜åº¦æ­£ç›¸å…³ â†’ è¯¥æ–¹æ³•æ›´ä¾èµ–è¯„å§”æ‰“åˆ†
    - å¦‚æœ method ä¸ judge_score ç›¸å…³æ€§è¾ƒå¼± â†’ è¯¥æ–¹æ³•å¯èƒ½æ›´åæ˜ å…¶ä»–å› ç´ ï¼ˆå¦‚ç²‰ä¸æŠ•ç¥¨ï¼‰

    æ³¨æ„ï¼šè¿™é‡Œç”¨çš„æ˜¯ judge_scoreï¼ˆåˆ†æ•°è¶Šé«˜è¶Šå¥½ï¼‰ï¼Œæ‰€ä»¥ï¼š
    - å¦‚æœ method_posï¼ˆæ’åè¶Šå°è¶Šå¥½ï¼‰ä¸ judge_score è´Ÿç›¸å…³ï¼Œè¯´æ˜åˆ†æ•°é«˜çš„æ’åé å‰ â†’ å¼ºä¾èµ–è¯„å§”
    - å¦‚æœç›¸å…³æ€§å¼±ï¼Œè¯´æ˜æ’åä¸å®Œå…¨ç”±è¯„å§”å†³å®š â†’ å¯èƒ½æ›´å—ç²‰ä¸å½±å“

    Args:
        df: æ•°æ®æ¡†
        method_col: å¾…è¯„ä¼°çš„æ–¹æ³•æ’ååˆ— (ä¾‹å¦‚ 'method1_pos' æˆ– 'method2_pos')
        judge_col: è¯„å§”åˆ†æ•°åˆ—
        min_contestants: æ¯å‘¨æœ€å°‘å‚èµ›äººæ•°

    Returns:
        åŒ…å«æ¯å‘¨ correlation (rho) çš„ DataFrame
    """
    results = []

    for (season, week), group in df.groupby(["season", "week"]):
        valid_data = group[[method_col, judge_col]].dropna()
        n = len(valid_data)

        if n < min_contestants:
            continue

        # è®¡ç®— Spearman ç›¸å…³ç³»æ•°
        # æ³¨æ„ï¼šmethod_pos è¶Šå°è¶Šå¥½ï¼Œjudge_score è¶Šå¤§è¶Šå¥½
        # æ‰€ä»¥æ­£å¸¸æƒ…å†µä¸‹åº”è¯¥æ˜¯è´Ÿç›¸å…³ï¼ˆåˆ†æ•°é«˜çš„æ’åé å‰ï¼‰
        rho, p_value = spearmanr(valid_data[method_col], valid_data[judge_col])

        results.append(
            {
                "season": season,
                "week": week,
                "n_contestants": n,
                "rho": rho,
                "p_value": p_value,
                "abs_rho": abs(rho),  # ç›¸å…³æ€§å¼ºåº¦ï¼ˆä¸è€ƒè™‘æ–¹å‘ï¼‰
            }
        )

    return pd.DataFrame(results)


def calculate_residual_correlation(
    df: pd.DataFrame,
    method_col: str,
    judge_col: str = "judge_score",
    placement_col: str = "placement",
    min_contestants: int = 4,
) -> pd.DataFrame:
    """
    è®¡ç®—"å»é™¤è¯„å§”å½±å“å"çš„ç›¸å…³æ€§åˆ†æ

    æ€è·¯ï¼š
    1. å…ˆçœ‹ judge_score ä¸ placement çš„å…³ç³»ï¼ˆè¯„å§”æ‰“åˆ†å¯¹æœ€ç»ˆç»“æœçš„å½±å“ï¼‰
    2. è®¡ç®—æ®‹å·®ï¼šactual_placement - predicted_by_judges
    3. çœ‹å“ªä¸ªæ–¹æ³•èƒ½æ›´å¥½åœ°è§£é‡Šè¿™ä¸ªæ®‹å·®

    å¦‚æœä¸€ä¸ªæ–¹æ³•èƒ½è§£é‡Šæ›´å¤šæ®‹å·® â†’ è¯´æ˜å®ƒæ•æ‰åˆ°äº†è¯„å§”åˆ†æ•°ä¹‹å¤–çš„å› ç´ ï¼ˆå¦‚ç²‰ä¸æŠ•ç¥¨ï¼‰
    """
    results = []

    for (season, week), group in df.groupby(["season", "week"]):
        valid_data = group[[method_col, judge_col, placement_col]].dropna()
        n = len(valid_data)

        if n < min_contestants:
            continue

        # è¯„å§”åˆ†æ•°ä¸æœ€ç»ˆæ’åçš„ç›¸å…³æ€§ï¼ˆåŸºå‡†ï¼‰
        rho_judge_placement, _ = spearmanr(
            valid_data[judge_col], valid_data[placement_col]
        )

        # æ–¹æ³•é¢„æµ‹ä¸æœ€ç»ˆæ’åçš„ç›¸å…³æ€§
        rho_method_placement, _ = spearmanr(
            valid_data[method_col], valid_data[placement_col]
        )

        # æ–¹æ³•é¢„æµ‹ä¸è¯„å§”åˆ†æ•°çš„ç›¸å…³æ€§
        rho_method_judge, p_val = spearmanr(
            valid_data[method_col], valid_data[judge_col]
        )

        # è®¡ç®—"è¶…å‡ºè¯„å§”å½±å“"çš„è§£é‡Šèƒ½åŠ›
        # ç®€åŒ–æŒ‡æ ‡ï¼šå¦‚æœæ–¹æ³•èƒ½é¢„æµ‹æœ€ç»ˆç»“æœï¼Œä½†ä¸å®Œå…¨ä¾èµ–è¯„å§”åˆ†æ•°
        # åˆ™ abs(rho_method_placement) é«˜ä½† abs(rho_method_judge) ç›¸å¯¹è¾ƒä½
        independence_score = abs(rho_method_placement) - abs(rho_method_judge)

        results.append(
            {
                "season": season,
                "week": week,
                "n_contestants": n,
                "rho_method_judge": rho_method_judge,
                "rho_method_placement": rho_method_placement,
                "rho_judge_placement": rho_judge_placement,
                "p_value": p_val,
                "independence_score": independence_score,  # è¶Šé«˜è¯´æ˜è¶Šä¸ä¾èµ–è¯„å§”
            }
        )

    return pd.DataFrame(results)


def compare_fan_favor(
    df_rank: pd.DataFrame, df_share: pd.DataFrame
) -> Tuple[Dict, pd.DataFrame]:
    """
    å¯¹æ¯”ä¸¤ç§æ–¹æ³•è°æ›´ favor fan votes

    åˆ¤æ–­æ ‡å‡†ï¼š
    1. ä¸è¯„å§”åˆ†æ•°çš„ç›¸å…³æ€§ï¼šè¶Šä½ â†’ è¶Šä¸ä¾èµ–è¯„å§” â†’ å¯èƒ½æ›´ä¾èµ–ç²‰ä¸
    2. Independence scoreï¼šè¶Šé«˜ â†’ è¶Šèƒ½è§£é‡Š"è¯„å§”ä¹‹å¤–"çš„å› ç´  â†’ å¯èƒ½æ˜¯ç²‰ä¸å½±å“
    """
    merged = pd.merge(
        df_rank,
        df_share,
        on=["season", "week"],
        suffixes=("_rank", "_share"),
    )

    # ç›¸å…³æ€§å·®å¼‚ï¼ˆShare - Rankï¼‰
    # å¦‚æœä¸ºè´Ÿï¼Œè¯´æ˜ Share ä¸è¯„å§”ç›¸å…³æ€§æ›´ä½ â†’ Share æ›´ä¸ä¾èµ–è¯„å§”
    merged["judge_corr_diff"] = abs(merged["rho_method_judge_share"]) - abs(
        merged["rho_method_judge_rank"]
    )

    # Independence score å·®å¼‚
    merged["independence_diff"] = (
        merged["independence_score_share"] - merged["independence_score_rank"]
    )

    stats = {
        "n_weeks": len(merged),
        # ä¸è¯„å§”åˆ†æ•°çš„å¹³å‡ç›¸å…³æ€§ï¼ˆç»å¯¹å€¼ï¼‰
        "mean_judge_corr_rank": abs(merged["rho_method_judge_rank"]).mean(),
        "mean_judge_corr_share": abs(merged["rho_method_judge_share"]).mean(),
        # Independence scores
        "mean_independence_rank": merged["independence_score_rank"].mean(),
        "mean_independence_share": merged["independence_score_share"].mean(),
        # å“ªä¸ªæ–¹æ³•æ›´ç‹¬ç«‹äºè¯„å§”ï¼Ÿ
        "share_less_judge_dependent": (merged["judge_corr_diff"] < 0).mean() * 100,  # %
        "rank_less_judge_dependent": (merged["judge_corr_diff"] > 0).mean() * 100,
        # å“ªä¸ªæ–¹æ³• independence score æ›´é«˜ï¼Ÿ
        "share_more_independent": (merged["independence_diff"] > 0).mean() * 100,
        "rank_more_independent": (merged["independence_diff"] < 0).mean() * 100,
        # å¹³å‡å·®å¼‚
        "mean_judge_corr_diff": merged["judge_corr_diff"].mean(),
        "mean_independence_diff": merged["independence_diff"].mean(),
    }

    return stats, merged


def print_report(stats: Dict, corr_rank: pd.DataFrame, corr_share: pd.DataFrame):
    """
    æ‰“å°åˆ†ææŠ¥å‘Šï¼šå“ªä¸ªæ–¹æ³•æ›´ favor fan votesï¼Ÿ
    """
    print("\n" + "=" * 60)
    print("ğŸ­  FAN VOTES FAVORITISM ANALYSIS: SHARE vs RANK")
    print("=" * 60)
    print(f"Total Weeks Analyzed: {stats['n_weeks']}")
    print("-" * 60)

    print(f"\n1. Correlation with Judge Scores (Lower = Less Judge-Dependent):")
    print(f"   - Rank Model:  {stats['mean_judge_corr_rank']:.4f}")
    print(f"   - Share Model: {stats['mean_judge_corr_share']:.4f}")

    if stats["mean_judge_corr_rank"] > stats["mean_judge_corr_share"]:
        diff = stats["mean_judge_corr_rank"] - stats["mean_judge_corr_share"]
        print(f"   â†’ Share Model is {diff:.4f} LESS dependent on judges âœ“")
    else:
        diff = stats["mean_judge_corr_share"] - stats["mean_judge_corr_rank"]
        print(f"   â†’ Rank Model is {diff:.4f} LESS dependent on judges âœ“")

    print("-" * 60)
    print(f"\n2. Independence Score (Higher = More Non-Judge Factors):")
    print(f"   - Rank Model:  {stats['mean_independence_rank']:.4f}")
    print(f"   - Share Model: {stats['mean_independence_share']:.4f}")

    if stats["mean_independence_share"] > stats["mean_independence_rank"]:
        diff = stats["mean_independence_share"] - stats["mean_independence_rank"]
        print(f"   â†’ Share Model explains {diff:.4f} MORE non-judge factors âœ“")
    else:
        diff = stats["mean_independence_rank"] - stats["mean_independence_share"]
        print(f"   â†’ Rank Model explains {diff:.4f} MORE non-judge factors âœ“")

    print("-" * 60)
    print(f"\n3. Week-by-Week Comparison:")
    print(
        f"   - Share Model less judge-dependent: {stats['share_less_judge_dependent']:.1f}%"
    )
    print(
        f"   - Rank Model less judge-dependent:  {stats['rank_less_judge_dependent']:.1f}%"
    )
    print()
    print(f"   - Share Model more independent: {stats['share_more_independent']:.1f}%")
    print(f"   - Rank Model more independent:  {stats['rank_more_independent']:.1f}%")

    print("-" * 60)
    print(f"\n4. Statistical Significance:")
    sig_rank = (corr_rank["p_value"] < 0.05).mean() * 100
    sig_share = (corr_share["p_value"] < 0.05).mean() * 100
    print(
        f"   - Rank-Judge correlation significant (p<0.05):  {sig_rank:.1f}% of weeks"
    )
    print(
        f"   - Share-Judge correlation significant (p<0.05): {sig_share:.1f}% of weeks"
    )

    print("=" * 60)

    # ç»¼åˆç»“è®º
    print("\nğŸ“Š CONCLUSION:")
    print("-" * 60)

    # åˆ¤æ–­å“ªä¸ªæ–¹æ³•æ›´ favor fan votes
    evidence_for_share = 0
    evidence_for_rank = 0

    if stats["mean_judge_corr_share"] < stats["mean_judge_corr_rank"]:
        evidence_for_share += 1
        print("âœ“ Share Model has WEAKER correlation with judge scores")
    else:
        evidence_for_rank += 1
        print("âœ“ Rank Model has WEAKER correlation with judge scores")

    if stats["mean_independence_share"] > stats["mean_independence_rank"]:
        evidence_for_share += 1
        print("âœ“ Share Model explains MORE non-judge factors")
    else:
        evidence_for_rank += 1
        print("âœ“ Rank Model explains MORE non-judge factors")

    if stats["share_less_judge_dependent"] > stats["rank_less_judge_dependent"]:
        evidence_for_share += 1
        print(
            f"âœ“ Share Model is less judge-dependent in {stats['share_less_judge_dependent']:.1f}% of weeks"
        )
    else:
        evidence_for_rank += 1
        print(
            f"âœ“ Rank Model is less judge-dependent in {stats['rank_less_judge_dependent']:.1f}% of weeks"
        )

    print("-" * 60)
    if evidence_for_share > evidence_for_rank:
        print(
            f"\nğŸ¯ ANSWER: The SHARE Model seems to favor fan votes MORE than Rank Model"
        )
        print(
            "   It is less dependent on judge scores and captures more non-judge factors."
        )
    elif evidence_for_rank > evidence_for_share:
        print(
            f"\nğŸ¯ ANSWER: The RANK Model seems to favor fan votes MORE than Share Model"
        )
        print(
            "   It is less dependent on judge scores and captures more non-judge factors."
        )
    else:
        print(f"\nğŸ¯ ANSWER: Both models show SIMILAR dependence on fan votes")
        print("   The difference is not substantial enough to draw a clear conclusion.")

    print("=" * 60)


def main():
    """æ‰§è¡Œ Fan Votes Favoritism åˆ†æ"""
    # 1. åŠ è½½æ•°æ®
    try:
        df = load_and_validate_data(INPUT_FILE)
    except Exception as e:
        print(e)
        return

    # 2. è®¡ç®—ä¸è¯„å§”åˆ†æ•°çš„ç›¸å…³æ€§
    print("\n=== Analyzing Rank Model's dependence on judge scores ===")
    corr_rank = calculate_residual_correlation(df, method_col="method1_pos")

    print("\n=== Analyzing Share Model's dependence on judge scores ===")
    corr_share = calculate_residual_correlation(df, method_col="method2_pos")

    # 3. å¯¹æ¯”åˆ†æ
    print("\n=== Comparing which method favors fan votes more ===")
    stats, comparison_df = compare_fan_favor(corr_rank, corr_share)

    # 4. è¾“å‡ºæŠ¥å‘Š
    print_report(stats, corr_rank, corr_share)

    # 5. ä¿å­˜ç»“æœ
    output_dir = OUTPUT_DIR / "question2_res" / "spearman"
    output_dir.mkdir(parents=True, exist_ok=True)

    corr_rank.to_csv(
        output_dir / "fan_favor_rank_method.csv", index=False, encoding="utf-8"
    )
    corr_share.to_csv(
        output_dir / "fan_favor_share_method.csv", index=False, encoding="utf-8"
    )
    comparison_df.to_csv(
        output_dir / "fan_favor_comparison.csv", index=False, encoding="utf-8"
    )

    print(f"\nâœ“ Detailed results saved to: {output_dir}")
    print(f"  - fan_favor_rank_method.csv")
    print(f"  - fan_favor_share_method.csv")
    print(f"  - fan_favor_comparison.csv")


if __name__ == "__main__":
    main()
