# 准确性检验报告：基于后验概率的淘汰预测准确性分析

## 概述

本报告基于贝叶斯推断得到的后验概率（p值），对模型预测选手是否会被淘汰的准确性进行了全面检验。

## 分析方法

### 数据来源
- **预测数据**: `q5_combined.csv` - 包含所有选手每周的预测淘汰概率和实际淘汰情况
- **阈值设定**: p ≥ 0.5 判定为预测淘汰，p < 0.5 判定为预测未淘汰

### 分析内容
1. **p值分布图**: 展示所有选手的预测淘汰概率，区分实际淘汰与未淘汰
2. **高概率聚焦图**: 专注于高淘汰概率区域（p ≥ 0.7），检验高置信度预测的准确性
3. **错误分析**: 识别和分析预测错误的案例

### 预测结果分类
- **True Positive (TP)**: 预测淘汰 + 实际淘汰 ✓
- **False Positive (FP)**: 预测淘汰 + 实际未淘汰 ✗ (高p但未淘汰)
- **True Negative (TN)**: 预测未淘汰 + 实际未淘汰 ✓
- **False Negative (FN)**: 预测未淘汰 + 实际淘汰 ✗ (低p但淘汰)

---

## 主要结果

### 1. 基于百分比的方法 (Season 3-27)

#### 准确率指标
- **总样本数**: 1,965
- **准确率 (Accuracy)**: 98.37%
- **精确率 (Precision)**: 90.64%
- **召回率 (Recall)**: 98.55%
- **F1分数**: 94.43%

#### 混淆矩阵
|              | 实际淘汰 | 实际未淘汰 |
|--------------|---------|----------|
| **预测淘汰**   | 271 (TP) | 28 (FP)  |
| **预测未淘汰** | 4 (FN)   | 1,662 (TN)|

#### 错误分析
- **总错误数**: 32 (占比 1.63%)
- **False Positive**: 28 (高p值但未淘汰)
  - 平均预测概率: 0.6485
  - 概率范围: 0.5089 - 0.7844
  - 分布广泛，跨越多个赛季
- **False Negative**: 4 (低p值但淘汰)
  - 平均预测概率: 0.3868
  - 概率范围: 0.3277 - 0.4338
  - 主要集中在 Season 3, 5, 6, 12

#### 关键发现
✓ **非常高的准确率** (98.37%)，模型预测非常可靠
✓ **高召回率** (98.55%)，几乎捕获了所有真正会被淘汰的选手
✓ **大部分错误是 FP**，即模型倾向于保守（宁可误判为淘汰也不漏判）
✓ **只有4个 FN**，说明模型很少遗漏真正会被淘汰的选手

---

### 2. 基于排名的方法 (其它赛季: 1, 2, 28-34)

#### 准确率指标
- **总样本数**: 658
- **准确率 (Accuracy)**: 95.74%
- **精确率 (Precision)**: 90.54%
- **召回率 (Recall)**: 76.14%
- **F1分数**: 82.72%

#### 混淆矩阵
|              | 实际淘汰 | 实际未淘汰 |
|--------------|---------|----------|
| **预测淘汰**   | 67 (TP)  | 7 (FP)   |
| **预测未淘汰** | 21 (FN)  | 563 (TN) |

#### 错误分析
- **总错误数**: 28 (占比 4.26%)
- **False Positive**: 7 (高p值但未淘汰)
  - 平均预测概率: 0.6403
  - 概率范围: 0.5148 - 0.8577
  - 主要集中在 Season 28, 31, 32, 34
- **False Negative**: 21 (低p值但淘汰)
  - 平均预测概率: 0.2456
  - 概率范围: 0.0400 - 0.4935
  - 分布较广，多个赛季都有

#### 关键发现
✓ **准确率依然很高** (95.74%)，但略低于百分比方法
⚠ **召回率较低** (76.14%)，有更多的 FN（漏判）
⚠ **21个 FN**，说明排名方法更容易漏掉真正会被淘汰的选手
✓ **FP较少**，当模型预测淘汰时，通常是正确的

---

## 图表说明

### 生成的图表文件

1. **`accuracy_check_pct.png`**
   - 百分比方法的完整p值分析图
   - 展示所有选手的预测概率分布
   - 红色点: 实际被淘汰
   - 蓝色点: 实际未被淘汰
   - X标记: 预测错误的点

2. **`accuracy_check_pct_high_p.png`**
   - 百分比方法的高概率区域分析 (p ≥ 0.7)
   - 聚焦高置信度预测
   - 验证高p值预测的可靠性

3. **`accuracy_check_rank.png`**
   - 排名方法的完整p值分析图
   - 与百分比方法图表结构相同

4. **`accuracy_check_rank_high_p.png`**
   - 排名方法的高概率区域分析 (p ≥ 0.7)

### 图表解读要点

- **纵轴**: 预测淘汰概率 (p值)，0-1之间
- **横轴**: 选手索引（按p值降序排列）
- **绿色虚线**: 阈值线 (p = 0.5)
- **理想情况**: 
  - 红色点（实际淘汰）应该集中在高p值区域
  - 蓝色点（未淘汰）应该集中在低p值区域
- **错误点**: 
  - 蓝色X: 高p但未淘汰 (FP)
  - 红色X: 低p但淘汰 (FN)

---

## 错误案例详细数据

### 数据文件
1. **`prediction_errors_pct.csv`** - 百分比方法的所有错误案例
2. **`prediction_errors_rank.csv`** - 排名方法的所有错误案例

### 错误案例特点

#### 百分比方法 FP案例（预测会淘汰但未淘汰）
- 大多数集中在后期周次（Week 9-11）
- 这些选手可能表现有起伏，但最终晋级
- p值范围: 0.51-0.78，大多在0.6-0.7之间

#### 百分比方法 FN案例（预测不会淘汰但被淘汰）
- 数量极少（仅4个）
- p值在0.33-0.43之间，接近阈值
- 这些可能是意外淘汰的案例

#### 排名方法 FN案例（预测不会淘汰但被淘汰）
- 数量较多（21个），是主要问题
- p值分布广泛: 0.04-0.49
- 说明排名方法在某些情况下过于乐观

---

## 结论与建议

### 主要结论

1. **两种方法都具有很高的准确率**
   - 百分比方法: 98.37%
   - 排名方法: 95.74%

2. **百分比方法表现更优**
   - 更高的准确率和召回率
   - 更少的错误案例（32 vs 28，但样本量更大）
   - 更好地识别会被淘汰的选手

3. **高p值预测非常可靠**
   - p ≥ 0.7 的预测准确率极高
   - 适合用于高置信度的淘汰预测

4. **错误模式不同**
   - 百分比方法: 主要是FP（保守，倾向于预测淘汰）
   - 排名方法: 更多FP（乐观，容易漏判淘汰）

### 实际应用建议

1. **优先使用百分比方法**（Season 3-27）
   - 准确率高，召回率高
   - 适合需要高可靠性的场景

2. **结合两种方法**
   - 对于有排名数据的赛季，可以同时参考两种方法
   - 当两种方法预测一致时，置信度更高

3. **关注p值阈值**
   - p ≥ 0.7: 高置信度淘汰
   - 0.5 ≤ p < 0.7: 中等置信度
   - p < 0.5: 预测不会淘汰

4. **特殊情况处理**
   - 对于p值接近0.5的案例，需要额外谨慎
   - 可以结合其他特征（如历史表现、观众投票趋势）辅助判断

---

## 技术细节

### 运行的脚本
1. **`q5_accuracy_check.py`** - 主要分析脚本
   - 计算准确率指标
   - 生成p值分析图
   - 导出错误案例

2. **`q5_error_summary.py`** - 错误总结脚本
   - 详细统计错误模式
   - 生成文字报告

### 输出文件位置
所有结果保存在: `src/output/question5_res/`

---

*报告生成时间: 2026-02-02*
*基于数据: q5_combined.csv (2,623 条记录)*
