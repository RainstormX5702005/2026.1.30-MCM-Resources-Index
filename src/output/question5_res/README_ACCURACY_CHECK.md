# 准确性检验使用说明

## 快速开始

### 运行完整分析
```bash
cd src
python q5_accuracy_check.py
```

这将生成：
- 4张p值分析图（PNG格式）
- 2个错误案例CSV文件
- 控制台输出详细统计信息

### 查看错误总结
```bash
python q5_error_summary.py
```

快速查看错误模式和统计信息。

---

## 生成的文件

### 图片文件（`src/output/question5_res/`）

1. **accuracy_check_pct.png**
   - 百分比方法（Season 3-27）的完整p值分析
   - 显示所有2000+个预测点
   
2. **accuracy_check_pct_high_p.png**
   - 百分比方法的高概率区域（p ≥ 0.7）
   - 聚焦高置信度预测
   
3. **accuracy_check_rank.png**
   - 排名方法（Season 1,2,28-34）的完整p值分析
   - 显示所有650+个预测点
   
4. **accuracy_check_rank_high_p.png**
   - 排名方法的高概率区域（p ≥ 0.7）

### 数据文件

5. **prediction_errors_pct.csv**
   - 百分比方法的32个错误案例详情
   - 列: Season, Week, Celebrity_Name(ID), 预测概率, 实际结果, 错误类型
   
6. **prediction_errors_rank.csv**
   - 排名方法的28个错误案例详情

7. **ACCURACY_CHECK_REPORT.md**
   - 完整的分析报告文档
   - 包含所有统计指标和解释

---

## 图表解读

### 颜色含义
- 🔴 **红色圆点**: 实际被淘汰的选手
- 🔵 **蓝色圆点**: 实际未被淘汰的选手
- 🔵 **蓝色叉号**: False Positive（预测淘汰但实际未淘汰）
- 🔴 **红色叉号**: False Negative（预测未淘汰但实际淘汰）
- 🟢 **绿色虚线**: 阈值线（p=0.5或0.7）

### 图表特点

**理想情况**:
- 红色点应该聚集在**高p值区域**（图的左侧上方）
- 蓝色点应该聚集在**低p值区域**（图的右侧下方）
- 叉号越少，预测越准确

**实际观察**:
✓ 百分比方法图：红色点大多在上方，蓝色点大多在下方，分界清晰
✓ 高概率图：几乎全是红色点，说明高p值预测非常准确
✗ 排名方法图：有更多的红色叉号，表示漏判较多

---

## 准确率指标说明

### 准确率 (Accuracy)
- **定义**: 正确预测的比例
- **公式**: (TP + TN) / 总数
- **百分比方法**: 98.37%
- **排名方法**: 95.74%

### 精确率 (Precision)
- **定义**: 预测为淘汰的样本中，实际淘汰的比例
- **公式**: TP / (TP + FP)
- **意义**: 当模型说"会淘汰"时，有多大概率是对的
- **百分比方法**: 90.64%
- **排名方法**: 90.54%

### 召回率 (Recall)
- **定义**: 实际淘汰的样本中，被正确预测的比例
- **公式**: TP / (TP + FN)
- **意义**: 能找出多少真正会被淘汰的选手
- **百分比方法**: 98.55% ⭐ 很少漏判
- **排名方法**: 76.14% ⚠️ 漏判较多

### F1分数
- **定义**: 精确率和召回率的调和平均数
- **公式**: 2 × (Precision × Recall) / (Precision + Recall)
- **百分比方法**: 94.43%
- **排名方法**: 82.72%

---

## 错误类型详解

### False Positive (FP) - 预测淘汰但实际未淘汰

**特征**:
- 这些选手被模型判断为会淘汰（p > 0.5）
- 但实际上他们晋级了
- 可能原因：临时表现不佳，但有强大的粉丝基础

**百分比方法**: 28个
- 平均p值: 0.65
- 大多数在0.5-0.7之间
- 分布在多个赛季和周次

**排名方法**: 7个
- 平均p值: 0.64
- 有一个高达0.86的异常值

### False Negative (FN) - 预测未淘汰但实际淘汰

**特征**:
- 这些选手被模型判断为不会淘汰（p < 0.5）
- 但实际上他们被淘汰了
- 可能原因：意外事件、粉丝投票不足、评委打分突然下降

**百分比方法**: 4个 ⭐ 非常少
- 平均p值: 0.39
- 都接近阈值0.5

**排名方法**: 21个 ⚠️ 较多
- 平均p值: 0.25
- 分布广泛，从0.04到0.49
- **这是排名方法的主要问题**

---

## 实际应用示例

### 场景1: 识别高风险选手
```
目标: 找出本周最可能被淘汰的选手

方法:
1. 查看p值图，找到p > 0.7的选手
2. 这些选手有很高概率被淘汰
3. 准确率接近90%

示例: Season 27 Week 9, Celebrity ID 31
- p = 0.7844
- 预测: 淘汰
- 实际: 未淘汰 (FP案例，但这种情况少见)
```

### 场景2: 评估预测可靠性
```
目标: 判断某个预测是否可信

规则:
- p ≥ 0.7: 高置信度，90%+准确
- 0.5 ≤ p < 0.7: 中等置信度，需谨慎
- p < 0.5: 预测不会淘汰

示例: Season 32 Week 11, Celebrity ID 9
- p = 0.7161
- 预测: 淘汰（中高置信度）
- 实际: 未淘汰 (FP案例)
- 建议: 结合其他信息辅助判断
```

### 场景3: 发现意外淘汰
```
目标: 识别可能被模型漏判的选手

关注:
- p < 0.5 但实际淘汰的案例（FN）
- 排名方法中较常见

示例: Season 34 Week 11, Celebrity ID 29
- p = 0.4935
- 预测: 不会淘汰
- 实际: 淘汰 (FN案例)
- 分析: 接近阈值，存在不确定性
```

---

## 修改和定制

### 调整阈值
编辑 `q5_accuracy_check.py`:
```python
# 第146行附近
threshold = 0.5  # 改为0.6或0.4
high_p_threshold = 0.7  # 改为0.8或0.6
```

### 筛选特定赛季
编辑 `q5_accuracy_check.py`:
```python
# 第158-162行
pct_df = combined_df[
    (combined_df['Season'] >= 3) & 
    (combined_df['Season'] <= 27) &  # 改为你想要的范围
    (combined_df['Prediction_Type'] == 'pct')
]
```

### 自定义图表样式
修改 `plot_p_value_analysis()` 函数中的matplotlib参数。

---

## 常见问题

### Q1: Celebrity_Name为什么是数字？
A: 在预测数据中，为了隐私和简化，使用了ID代替真实姓名。可以通过Season和Week信息在原始数据中查找对应的选手。

### Q2: 为什么两种方法的赛季不同？
A: 
- 百分比方法适用于有详细百分比数据的赛季（Season 3-27）
- 排名方法用于早期赛季（1-2）和最新赛季（28-34）

### Q3: 如何理解"保守"和"乐观"？
A:
- **保守**（百分比方法）: 更倾向于预测淘汰，宁可误报也不漏报
- **乐观**（排名方法）: 更倾向于预测晋级，容易漏掉真正会淘汰的选手

### Q4: 哪个方法更好？
A: 百分比方法在所有指标上都更优，特别是召回率（98.55% vs 76.14%）。如果只能选一个，推荐百分比方法。

---

## 进一步分析建议

1. **时间序列分析**
   - 检查不同周次的预测准确率
   - 是否后期周次更容易预测？

2. **特征重要性**
   - 哪些特征对预测影响最大？
   - 评委打分 vs 观众投票

3. **异常案例深入分析**
   - 详细研究FP和FN案例
   - 是否有共同特征？

4. **模型改进**
   - 结合两种方法的优势
   - 对于接近阈值的案例增加特征权重

---

*使用说明更新日期: 2026-02-02*
