"""
è´å¶æ–¯å±‚æ¬¡æ¨¡å‹ + MCMC æ¨æ–­ç²‰ä¸æŠ•ç¥¨å¼ºåº¦
å®Œæ•´ç‰ˆæœ¬ - ä½¿ç”¨ C ç¼–è¯‘åŠ é€Ÿï¼Œå¤šæ ¸å¹¶è¡Œé‡‡æ ·
"""

import os

os.environ.setdefault(
    "PYTENSOR_FLAGS", "device=cpu,floatX=float64,optimizer=fast_compile"
)

import numpy as np
import pandas as pd
import pymc as pm
import pytensor.tensor as pt
import arviz as az
import multiprocessing as mp
from typing import Dict, List, Tuple
from dataclasses import dataclass

from configs.config import OUTPUT_DIR

# è®¾ç½®éšæœºç§å­
np.random.seed(42)


@dataclass
class MCMCConfig:
    """MCMC é‡‡æ ·é…ç½®"""

    draws: int = 500
    tune: int = 500
    chains: int = 8
    cores: int = -1
    target_accept: float = 0.85
    init: str = "jitter+adapt_diag"  # æ›´ç¨³å®šçš„åˆå§‹åŒ–æ–¹æ³•

    def __post_init__(self):
        if self.cores == -1:
            self.cores = min(mp.cpu_count(), self.chains)


def load_preprocessed_data(
    file_name: str = "preprocessed_data_percentage.csv",
) -> pd.DataFrame:
    """åŠ è½½é¢„å¤„ç†åçš„æ•°æ®"""
    file_path = OUTPUT_DIR / "preprocessed" / file_name

    try:
        df = pd.read_csv(file_path, encoding="utf-8")
        return df
    except FileNotFoundError as e:
        raise


def prepare_indices(df: pd.DataFrame) -> Tuple[Dict, int, int]:
    """
    å‡†å¤‡èµ›å­£å’Œé€‰æ‰‹ç´¢å¼•

    Returns:
        (season_map, n_seasons, n_contestants)
    """
    seasons = sorted(df["season"].unique())
    season_map = {s: i for i, s in enumerate(seasons)}

    df["season_idx"] = df["season"].map(season_map)
    df["contestant_id"] = range(len(df))

    n_seasons = len(seasons)
    n_contestants = len(df)

    return season_map, n_seasons, n_contestants


def extract_features(
    df: pd.DataFrame, n_contestants: int
) -> Tuple[np.ndarray, np.ndarray]:
    """
    ç›´æ¥ä»é¢„å¤„ç†æ•°æ®ä¸­æå–ç‰¹å¾ï¼ˆä¸é‡å¤ç¼–ç ï¼‰

    Returns:
        (X_industry, X_age)
    """
    industry_cols = [c for c in df.columns if "celebrity_industry_" in c]
    if len(industry_cols) > 0:
        X_industry = df[industry_cols].values.astype(np.float64)
    else:
        X_industry = np.zeros((n_contestants, 1), dtype=np.float64)

    if "celebrity_age_during_season" in df.columns:
        X_age = df["celebrity_age_during_season"].fillna(0).values.astype(np.float64)
    else:
        X_age = np.zeros(n_contestants, dtype=np.float64)

    return X_industry, X_age


def build_observation_data(
    df: pd.DataFrame,
    max_weeks: int = 11,
) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, Dict]:
    """
    æ„å»ºé•¿æ ¼å¼è§‚æµ‹æ•°æ®

    Returns:
        (obs_season_idx, obs_week_idx, obs_contestant_idx, obs_percentage, flat_idx_map)
    """
    obs_season_idx = []
    obs_week_idx = []
    obs_contestant_idx = []
    obs_percentage = []
    flat_idx_map = {}
    current_flat_idx = 0

    for idx, row in df.iterrows():
        c_id = row["contestant_id"]
        s_idx = row["season_idx"]

        for w in range(1, max_weeks + 1):
            col_pct = f"week{w}_percentage"

            if col_pct in df.columns:
                pct_val = row[col_pct]

                if pd.notna(pct_val) and pct_val > 0:
                    obs_season_idx.append(s_idx)
                    obs_week_idx.append(w - 1)
                    obs_contestant_idx.append(c_id)
                    obs_percentage.append(pct_val)
                    flat_idx_map[(c_id, w)] = current_flat_idx
                    current_flat_idx += 1

    return (
        np.array(obs_season_idx, dtype=np.int32),
        np.array(obs_week_idx, dtype=np.int32),
        np.array(obs_contestant_idx, dtype=np.int32),
        np.array(obs_percentage, dtype=np.float64),
        flat_idx_map,
    )


def build_elimination_pairs(
    df: pd.DataFrame,
    season_map: Dict,
    flat_idx_map: Dict,
    max_weeks: int = 11,
) -> Tuple[np.ndarray, Dict]:
    """
    æ„å»ºæ·˜æ±°çº¦æŸé…å¯¹ï¼ˆé¿å…ä¿¡æ¯æ³„éœ²ï¼‰

    é€»è¾‘ï¼š
    1. **ä¸ä½¿ç”¨ placement**ï¼ˆæœ€ç»ˆæ’åï¼‰ï¼Œé¿å…æœªæ¥ä¿¡æ¯æ³„éœ²
    2. åªçœ‹é€‰æ‰‹æ˜¯å¦åœ¨ä¸‹å‘¨è¿˜æœ‰æ•°æ®ï¼š
       - è¢«æ·˜æ±°ï¼šweeks_participated == w ä¸” w < season_total_weeks
       - æ™‹çº§ï¼šweeks_participated > w
    3. çº¦æŸï¼šåœ¨åŒä¸€å‘¨å†…ï¼Œæ™‹çº§è€…çš„ç»¼åˆå¾—åˆ† > è¢«æ·˜æ±°è€…

    Returns:
        (elimination_pairs, pair_info)
        - elimination_pairs: [[winner_idx, loser_idx], ...]
        - pair_info: {pair_idx: {"winner": name, "loser": name, "week": w, "season": s}}
    """
    elimination_pairs = []
    pair_info = {}  # ç”¨äºè°ƒè¯•éªŒè¯
    pair_idx = 0

    for s in df["season"].unique():
        s_df = df[df["season"] == s]
        season_total_weeks = s_df["season_total_weeks"].iloc[0]

        # éå†æ¯ä¸€å‘¨ï¼ˆé™¤äº†æœ€åä¸€å‘¨ï¼Œå› ä¸ºæœ€åä¸€å‘¨æ²¡æœ‰æ·˜æ±°ï¼‰
        for w in range(1, min(max_weeks, season_total_weeks)):
            week_contestants = []

            for _, row in s_df.iterrows():
                c_id = row["contestant_id"]

                # æ£€æŸ¥æœ¬å‘¨æ˜¯å¦æœ‰è§‚æµ‹æ•°æ®
                if (c_id, w) not in flat_idx_map:
                    continue

                flat_idx = flat_idx_map[(c_id, w)]
                weeks_part = row["weeks_participated"]

                week_contestants.append(
                    {
                        "flat_idx": flat_idx,
                        "weeks_participated": weeks_part,
                        "contestant_id": c_id,
                        "name": row["celebrity_name"],
                    }
                )

            # åˆ†ç¦»æ™‹çº§è€…å’Œæ·˜æ±°è€…ï¼ˆä¸çœ‹ placementï¼ï¼‰
            advanced = []  # æ™‹çº§è€…
            eliminated = []  # æ·˜æ±°è€…

            for c in week_contestants:
                if c["weeks_participated"] == w:
                    # æœ¬å‘¨æ˜¯æœ€åä¸€å‘¨ = è¢«æ·˜æ±°
                    eliminated.append(c)
                elif c["weeks_participated"] > w:
                    # ç»§ç»­å‚èµ› = æ™‹çº§
                    advanced.append(c)

            # ç”Ÿæˆé…å¯¹ï¼šæ¯ä¸ªæ™‹çº§è€… vs æ¯ä¸ªè¢«æ·˜æ±°è€…
            for winner in advanced:
                for loser in eliminated:
                    elimination_pairs.append([winner["flat_idx"], loser["flat_idx"]])
                    pair_info[pair_idx] = {
                        "winner": winner["name"],
                        "loser": loser["name"],
                        "week": w,
                        "season": s,
                    }
                    pair_idx += 1

    return (
        (
            np.array(elimination_pairs, dtype=np.int32)
            if elimination_pairs
            else np.array([], dtype=np.int32).reshape(0, 2)
        ),
        pair_info,
    )


def build_pymc_model(
    obs_season_idx: np.ndarray,
    obs_week_idx: np.ndarray,
    obs_contestant_idx: np.ndarray,
    obs_percentage: np.ndarray,
    X_industry: np.ndarray,
    X_age: np.ndarray,
    elimination_pairs: np.ndarray,
    n_seasons: int,
    n_contestants: int,
    n_observations: int,
) -> pm.Model:
    """
    æ„å»ºå®Œæ•´çš„è´å¶æ–¯å±‚æ¬¡æ¨¡å‹

    æ¨¡å‹ç»“æ„ï¼š
    - season_trend: èµ›å­£è¶‹åŠ¿ (Gaussian Random Walk)
    - beta_week: å‘¨æ¬¡æ•ˆåº”
    - alpha: é€‰æ‰‹åŸºç¡€äººæ°”ï¼ˆç®€å•å…ˆéªŒï¼‰
    - beta_judge: è¯„å§”åˆ†æƒé‡
    - beta_industry: èŒä¸šç‰¹å¾æƒé‡
    - beta_age: å¹´é¾„æƒé‡
    - V_latent: æ½œåœ¨æŠ•ç¥¨å¼ºåº¦ (Gamma åˆ†å¸ƒ)
    - constraint: æ·˜æ±°çº¦æŸ (Bernoulli)
    """
    n_industry_features = X_industry.shape[1]
    n_pairs = len(elimination_pairs)

    with pm.Model() as model:

        # 1. èµ›å­£è¶‹åŠ¿ (Gaussian Random Walk)
        sigma_season = pm.HalfNormal("sigma_season", sigma=0.3)
        season_trend = pm.GaussianRandomWalk(
            "season_trend",
            sigma=sigma_season,
            shape=n_seasons,
            init_dist=pm.Normal.dist(0, 0.1),
        )

        beta_week = pm.Normal("beta_week", mu=0, sigma=0.1)

        theta = pm.Normal("theta", mu=0, sigma=0.2)
        sigma_alpha = pm.HalfNormal("sigma_alpha", sigma=0.5)
        alpha = pm.Normal(
            "alpha",
            mu=theta,
            sigma=sigma_alpha,
            shape=n_contestants,
        )

        # 4. è¯„å§”åˆ†æƒé‡
        beta_judge = pm.Normal("beta_judge", mu=0.5, sigma=0.3)

        # 5. èŒä¸šç‰¹å¾æƒé‡
        beta_ind = pm.Normal("beta_ind", mu=0, sigma=0.3, shape=n_industry_features)

        # 6. å¹´é¾„æƒé‡
        beta_age = pm.Normal("beta_age", mu=0, sigma=0.3)

        # === Log-Linear æ¨¡å‹ï¼ˆæŠ•ç¥¨å¼ºåº¦ï¼‰ ===
        log_mu = (
            alpha[obs_contestant_idx]
            + beta_judge * obs_percentage
            + pm.math.dot(X_industry, beta_ind)[obs_contestant_idx]
            + beta_age * X_age[obs_contestant_idx]
            + season_trend[obs_season_idx]
            + beta_week * obs_week_idx
        )

        # æ½œåœ¨ç¥¨æ•°å¼ºåº¦ (Gamma åˆ†å¸ƒ)
        phi = pm.HalfNormal("phi", sigma=3.0)
        mu_ = pm.math.exp(log_mu)
        V_latent = pm.Gamma(
            "V_latent",
            alpha=phi,
            beta=phi / mu_,
            shape=n_observations,
        )

        # === æ·˜æ±°çº¦æŸ ===
        if n_pairs > 0:
            winners_idx = elimination_pairs[:, 0]
            losers_idx = elimination_pairs[:, 1]

            # çº¦æŸï¼šæ™‹çº§è€…çš„ç»¼åˆå¾—åˆ† > æ·˜æ±°è€…
            diff = (obs_percentage[winners_idx] - obs_percentage[losers_idx]) + 0.5 * (
                pt.log(V_latent[winners_idx]) - pt.log(V_latent[losers_idx])
            )

            # Sigmoid æ¦‚ç‡çº¦æŸ
            p_outcome = pm.math.sigmoid(diff * 5)
            pm.Bernoulli(
                "constraint",
                p=p_outcome,
                observed=np.ones(n_pairs, dtype=np.int32),
            )

    return model


def run_mcmc_sampling(model: pm.Model, config: MCMCConfig) -> az.InferenceData:
    """è¿è¡Œ MCMC é‡‡æ ·"""
    print(f"ğŸš€ Starting MCMC sampling with {config.cores} cores...")
    print(f"   Chains: {config.chains}, Draws: {config.draws}, Tune: {config.tune}")
    print(f"   Init: {config.init}")

    with model:
        trace = pm.sample(
            draws=config.draws,
            tune=config.tune,
            chains=config.chains,
            cores=config.cores,
            target_accept=config.target_accept,
            init=config.init,
            return_inferencedata=True,
            progressbar=True,
        )

    return trace


def extract_results(
    trace: az.InferenceData,
    df: pd.DataFrame,
    obs_season_idx: np.ndarray,
    obs_week_idx: np.ndarray,
    obs_contestant_idx: np.ndarray,
    obs_percentage: np.ndarray,
    season_map: Dict,
) -> pd.DataFrame:
    """æå–æ¨æ–­ç»“æœ"""
    # æå–æ½œåœ¨ç¥¨æ•°åéªŒ
    v_samples = trace.posterior["V_latent"].values  # (chains, draws, observations)
    v_mean = v_samples.mean(axis=(0, 1))
    v_std = v_samples.std(axis=(0, 1))
    v_lower = np.percentile(v_samples, 2.5, axis=(0, 1))
    v_upper = np.percentile(v_samples, 97.5, axis=(0, 1))

    # åè½¬ season_map
    inv_season_map = {v: k for k, v in season_map.items()}

    # æ„é€ ç»“æœè¡¨
    results = []
    for i in range(len(obs_percentage)):
        c_idx = obs_contestant_idx[i]
        celeb_name = df.loc[df["contestant_id"] == c_idx, "celebrity_name"].values[0]

        results.append(
            {
                "season": inv_season_map[obs_season_idx[i]],
                "week": obs_week_idx[i] + 1,
                "celebrity_name": celeb_name,
                "contestant_id": c_idx,
                "judge_score_pct": obs_percentage[i],
                "vote_intensity_mean": v_mean[i],
                "vote_intensity_std": v_std[i],
                "vote_intensity_lower_95": v_lower[i],
                "vote_intensity_upper_95": v_upper[i],
            }
        )

    result_df = pd.DataFrame(results)

    # æ’åº
    result_df = result_df.sort_values(
        ["season", "week", "vote_intensity_mean"],
        ascending=[True, True, False],
    ).reset_index(drop=True)

    return result_df


def save_results(df: pd.DataFrame, output_file: str) -> None:
    """ä¿å­˜ç»“æœ"""
    output_path = OUTPUT_DIR / "trained" / output_file
    output_path.parent.mkdir(parents=True, exist_ok=True)

    df.to_csv(output_path, index=False)
    print(f"âœ… Results saved to: {output_path}")


def main():
    """ä¸»å‡½æ•°ï¼šæ‰§è¡Œå®Œæ•´çš„è´å¶æ–¯ MCMC æ¨æ–­æµç¨‹"""

    INPUT_FILE = "preprocessed_data_percentage.csv"
    OUTPUT_FILE = "bayesian_vote_intensity.csv"
    MAX_WEEKS = 11

    n_cores = mp.cpu_count()
    mcmc_config = MCMCConfig(
        draws=500,
        tune=500,
        chains=min(n_cores, 8),
        cores=min(n_cores, 8),
        target_accept=0.9,
        init="advi+adapt_diag",
    )

    print("=" * 60)
    print("ğŸ”¥ Bayesian Hierarchical Model + MCMC Inference")
    print(f"   Using {mcmc_config.cores} CPU cores (max available: {n_cores})")
    print("   C++ compilation enabled for acceleration")
    print("=" * 60)

    # [1/8] åŠ è½½æ•°æ®
    print("\n[1/8] Loading preprocessed data...")
    df = load_preprocessed_data(INPUT_FILE)

    # [2/8] å‡†å¤‡ç´¢å¼•
    print("\n[2/8] Preparing indices...")
    season_map, n_seasons, n_contestants = prepare_indices(df)
    print(f"      Seasons: {n_seasons}, Contestants: {n_contestants}")

    # [3/8] æå–ç‰¹å¾
    print("\n[3/8] Extracting features...")
    X_industry, X_age = extract_features(df, n_contestants)
    print(f"      Industry features: {X_industry.shape[1]}")

    # [4/8] æ„å»ºè§‚æµ‹æ•°æ®
    print("\n[4/8] Building observation data...")
    obs_season_idx, obs_week_idx, obs_contestant_idx, obs_percentage, flat_idx_map = (
        build_observation_data(df, MAX_WEEKS)
    )
    n_observations = len(obs_percentage)
    print(f"      Observations: {n_observations}")

    # [5/8] æ„å»ºæ·˜æ±°çº¦æŸ
    print("\n[5/8] Building elimination constraints...")
    elimination_pairs, pair_info = build_elimination_pairs(
        df, season_map, flat_idx_map, MAX_WEEKS
    )

    # æ‰“å°éªŒè¯ä¿¡æ¯ï¼ˆå‰5ä¸ªé…å¯¹ï¼‰
    if len(elimination_pairs) > 0:
        print(f"      Total pairs: {len(elimination_pairs)}")
        print(f"      Sample pairs (éªŒè¯æ— ä¿¡æ¯æ³„éœ²):")
        for i in range(min(5, len(elimination_pairs))):
            info = pair_info[i]
            print(
                f"        Week {info['week']}, Season {info['season']}: {info['winner']} (æ™‹çº§) > {info['loser']} (æ·˜æ±°)"
            )

    # é™åˆ¶çº¦æŸæ•°é‡ä»¥åŠ é€Ÿï¼ˆéšæœºé‡‡æ ·ï¼‰
    MAX_PAIRS = 200
    if len(elimination_pairs) > MAX_PAIRS:
        idx = np.random.choice(len(elimination_pairs), MAX_PAIRS, replace=False)
        elimination_pairs = elimination_pairs[idx]
        print(f"      Sampled pairs for efficiency: {len(elimination_pairs)}")

    # [6/8] æ„å»º PyMC æ¨¡å‹
    print("\n[6/8] Building PyMC model...")
    model = build_pymc_model(
        obs_season_idx=obs_season_idx,
        obs_week_idx=obs_week_idx,
        obs_contestant_idx=obs_contestant_idx,
        obs_percentage=obs_percentage,
        X_industry=X_industry,
        X_age=X_age,
        elimination_pairs=elimination_pairs,
        n_seasons=n_seasons,
        n_contestants=n_contestants,
        n_observations=n_observations,
    )
    print("      Model built successfully!")

    # [7/8] è¿è¡Œ MCMC é‡‡æ ·
    print("\n[7/8] Running MCMC sampling...")
    trace = run_mcmc_sampling(model, mcmc_config)
    print("      Sampling completed!")

    # [8/8] æå–å¹¶ä¿å­˜ç»“æœ
    print("\n[8/8] Extracting and saving results...")
    result_df = extract_results(
        trace=trace,
        df=df,
        obs_season_idx=obs_season_idx,
        obs_week_idx=obs_week_idx,
        obs_contestant_idx=obs_contestant_idx,
        obs_percentage=obs_percentage,
        season_map=season_map,
    )
    save_results(result_df, OUTPUT_FILE)

    print("\n" + "=" * 60)
    print("ğŸ‰ Bayesian MCMC inference completed!")
    print(f"   Total rows: {len(result_df)}")
    print("=" * 60)

    # æ‰“å°ç¤ºä¾‹ç»“æœ
    print("\nğŸ“Š Sample results (first 10 rows):")
    print(
        result_df[
            [
                "celebrity_name",
                "season",
                "week",
                "judge_score_pct",
                "vote_intensity_mean",
            ]
        ]
        .head(10)
        .to_string(index=False)
    )


if __name__ == "__main__":
    main()
