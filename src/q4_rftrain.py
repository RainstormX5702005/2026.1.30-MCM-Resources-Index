import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import (
    train_test_split,
    GridSearchCV,
    cross_validate,
    KFold,
)
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.pipeline import Pipeline

import lightgbm as lgb
import joblib
import re

from configs.config import DATA_DIR, OUTPUT_DIR


def rf_train(
    X: pd.DataFrame, y: pd.Series, feature_type: str = "rank", output_dir=None
):
    """ä½¿ç”¨Pipelineè¿›è¡Œéšæœºæ£®æ—è®­ç»ƒ

    Args:
        X: ç‰¹å¾æ•°æ®
        y: ç›®æ ‡å˜é‡
        feature_type: ç‰¹å¾ç±»å‹ï¼Œ"rank" æˆ– "pct"
        output_dir: è¾“å‡ºç›®å½•ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨OUTPUT_DIR
    """
    if output_dir is None:
        output_dir = OUTPUT_DIR
    print(f"\n{'='*70}")
    print(f"è®­ç»ƒ {feature_type.upper()} ç‰¹å¾çš„éšæœºæ£®æ—æ¨¡å‹")
    print(f"{'='*70}")

    # æ•°æ®åˆ’åˆ†
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.3, random_state=42
    )

    print(f"\næ•°æ®åˆ’åˆ†:")
    print(f"  è®­ç»ƒé›†: {X_train.shape[0]} æ ·æœ¬ Ã— {X_train.shape[1]} ç‰¹å¾")
    print(f"  æµ‹è¯•é›†: {X_test.shape[0]} æ ·æœ¬ Ã— {X_test.shape[1]} ç‰¹å¾")

    # æ„å»ºPipeline
    pipeline = Pipeline(
        [
            ("scaler", StandardScaler()),
            ("rf", RandomForestRegressor(random_state=42, n_jobs=-1)),
        ]
    )

    # è¶…å‚æ•°ç½‘æ ¼æœç´¢ç©ºé—´ï¼ˆåŸºäºä¹‹å‰RandomizedSearchçš„ç»“æœä¼˜åŒ–ï¼‰
    param_grid = {
        "rf__n_estimators": [200, 300, 500],
        "rf__max_depth": [12, 14, 16],
        "rf__min_samples_split": [2, 3, 4],
        "rf__min_samples_leaf": [3, 5],
        "rf__max_features": ["sqrt", None],
    }

    # ä½¿ç”¨GridSearchCVè¿›è¡Œç½‘æ ¼æœç´¢
    print(f"\næ‰§è¡Œç½‘æ ¼æœç´¢...")
    print(
        f"å‚æ•°ç»„åˆæ€»æ•°: {len(param_grid['rf__n_estimators']) * len(param_grid['rf__max_depth']) * len(param_grid['rf__min_samples_split']) * len(param_grid['rf__min_samples_leaf']) * len(param_grid['rf__max_features'])}"
    )

    inner_cv = KFold(n_splits=5, random_state=42, shuffle=True)
    search = GridSearchCV(
        pipeline,
        param_grid,
        cv=inner_cv,
        scoring="r2",
        n_jobs=-1,
        verbose=2,
        return_train_score=True,
    )

    search.fit(X_train, y_train)

    print(f"\næœ€ä¼˜å‚æ•°: {search.best_params_}")
    print(f"æœ€ä¼˜CVå¾—åˆ† (RÂ²): {search.best_score_:.4f}")

    # æ˜¾ç¤ºTop 5å‚æ•°ç»„åˆ
    print(f"\nTop 5 å‚æ•°ç»„åˆ:")
    results_df = pd.DataFrame(search.cv_results_)
    results_df = results_df.sort_values("rank_test_score")
    for idx, row in results_df.head(5).iterrows():
        print(
            f"  Rank {int(row['rank_test_score'])}: RÂ²={row['mean_test_score']:.4f} (Â±{row['std_test_score']:.4f}), params={row['params']}"
        )

    # åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°
    best_model = search.best_estimator_
    y_pred = best_model.predict(X_test)

    mse = mean_squared_error(y_test, y_pred)
    rmse = np.sqrt(mse)
    r2 = r2_score(y_test, y_pred)

    print(f"\næµ‹è¯•é›†æ€§èƒ½:")
    print(f"  RMSE: {rmse:.6f}")
    print(f"  RÂ²: {r2:.6f}")

    # 10æŠ˜äº¤å‰éªŒè¯æ£€æŸ¥è¿‡æ‹Ÿåˆ
    print(f"\næ‰§è¡Œ10æŠ˜äº¤å‰éªŒè¯...")
    cv_10fold = KFold(n_splits=10, random_state=42, shuffle=True)
    cv_results = cross_validate(
        best_model,
        X,
        y,
        cv=cv_10fold,
        scoring=["r2", "neg_mean_squared_error"],
        n_jobs=-1,
        return_train_score=True,
    )

    train_r2_mean = cv_results["train_r2"].mean()
    train_r2_std = cv_results["train_r2"].std()
    test_r2_mean = cv_results["test_r2"].mean()
    test_r2_std = cv_results["test_r2"].std()
    train_rmse_mean = np.sqrt(-cv_results["train_neg_mean_squared_error"].mean())
    test_rmse_mean = np.sqrt(-cv_results["test_neg_mean_squared_error"].mean())

    print(f"\n10æŠ˜äº¤å‰éªŒè¯ç»“æœ:")
    print(f"  è®­ç»ƒé›† RÂ²: {train_r2_mean:.4f} Â± {train_r2_std:.4f}")
    print(f"  éªŒè¯é›† RÂ²: {test_r2_mean:.4f} Â± {test_r2_std:.4f}")
    print(f"  è®­ç»ƒé›† RMSE: {train_rmse_mean:.6f}")
    print(f"  éªŒè¯é›† RMSE: {test_rmse_mean:.6f}")

    # è¿‡æ‹Ÿåˆæ£€æŸ¥
    overfit_gap = train_r2_mean - test_r2_mean
    print(f"\nè¿‡æ‹Ÿåˆæ£€æŸ¥:")
    print(f"  è®­ç»ƒé›†ä¸éªŒè¯é›†RÂ²å·®è·: {overfit_gap:.4f}")
    if overfit_gap > 0.1:
        print(f"  âš ï¸  è­¦å‘Š: å¯èƒ½å­˜åœ¨è¿‡æ‹Ÿåˆ (å·®è· > 0.1)")
    elif overfit_gap > 0.05:
        print(f"  âš¡ æ³¨æ„: è½»å¾®è¿‡æ‹Ÿåˆå€¾å‘ (å·®è· > 0.05)")
    else:
        print(f"  âœ“ æ¨¡å‹æ³›åŒ–èƒ½åŠ›è‰¯å¥½")

    # ç‰¹å¾é‡è¦æ€§åˆ†æ
    print(f"\nç‰¹å¾é‡è¦æ€§åˆ†æ:")
    rf_model = best_model.named_steps["rf"]
    feature_importance = pd.DataFrame(
        {"feature": X.columns, "importance": rf_model.feature_importances_}
    ).sort_values("importance", ascending=False)

    print(f"\nTop 20 æœ€é‡è¦ç‰¹å¾:")
    for idx, row in feature_importance.head(20).iterrows():
        print(f"  {row['feature']:40s}: {row['importance']:.6f}")

    # ä¿å­˜ç‰¹å¾é‡è¦æ€§
    importance_path = output_dir / f"feature_importance_{feature_type}.csv"
    feature_importance.to_csv(importance_path, index=False, encoding="utf-8")
    print(f"\nâœ“ å®Œæ•´ç‰¹å¾é‡è¦æ€§å·²ä¿å­˜åˆ°: {importance_path}")

    # ä¿å­˜æ¨¡å‹
    model_path = output_dir / f"rf_model_{feature_type}.pkl"
    joblib.dump(best_model, model_path)
    print(f"âœ“ æ¨¡å‹å·²ä¿å­˜åˆ°: {model_path}")

    return best_model, {
        "feature_type": feature_type,
        "n_samples_train": len(X_train),
        "n_samples_test": len(X_test),
        "n_features": X.shape[1],
        "best_params": search.best_params_,
        "cv_score": search.best_score_,
        "test_rmse": rmse,
        "test_r2": r2,
        "cv10_train_r2_mean": train_r2_mean,
        "cv10_train_r2_std": train_r2_std,
        "cv10_test_r2_mean": test_r2_mean,
        "cv10_test_r2_std": test_r2_std,
        "cv10_train_rmse": train_rmse_mean,
        "cv10_test_rmse": test_rmse_mean,
        "overfit_gap": overfit_gap,
        "top_10_features": feature_importance.head(10)[
            ["feature", "importance"]
        ].to_dict("records"),
    }


def main():
    """
    Q4 éšæœºæ£®æ—æ¨¡å‹è®­ç»ƒï¼šåˆ†æèˆä¼´å’Œé€‰æ‰‹ç‰¹å¾å¯¹è¯„å§”è¯„åˆ†å’Œç²‰ä¸æŠ•ç¥¨çš„å½±å“

    é—®é¢˜æ ¸å¿ƒï¼š
    - How much do such things (pro dancers, celebrity characteristics) impact
      how well a celebrity will do in the competition?
    - Do they impact judges scores and fan votes in the same way?

    å»ºæ¨¡æ€è·¯ï¼š
    - å› å˜é‡1: è¯„å§”è¯„åˆ†å‡å€¼ï¼ˆjudge_score_meanï¼‰â†’ è½¬æ¢ä¸ºæ’å/ç™¾åˆ†æ¯”
    - å› å˜é‡2: è§‚ä¼—æŠ•ç¥¨å‡å€¼ï¼ˆaudience_votes_meanï¼‰â†’ è½¬æ¢ä¸ºæ’å/ç™¾åˆ†æ¯”
    - è‡ªå˜é‡: é™æ€ç‰¹å¾ + ç¬¬ä¸€å‘¨å’Œç¬¬äºŒå‘¨çš„æ’å/ç™¾åˆ†æ¯”è¡¨ç°

    é€šè¿‡åŠ å…¥æ—©æœŸè¡¨ç°ç‰¹å¾ï¼Œåˆ†æï¼š
    1. é™æ€ç‰¹å¾åœ¨æ§åˆ¶è¡¨ç°åçš„ç‹¬ç«‹è´¡çŒ®
    2. é™æ€ç‰¹å¾é‡è¦æ€§æ˜¯å¦è¢«è¡¨ç°ç‰¹å¾"æŒ¤å‹"
    3. èˆä¼´å’Œé€‰æ‰‹ç‰¹å¾å¯¹è¯„å§”å’Œç²‰ä¸çš„çœŸå®å½±å“
    """

    # å®šä¹‰è¾“å‡ºç›®å½•
    output_dir = OUTPUT_DIR / "question4_res"
    output_dir.mkdir(parents=True, exist_ok=True)

    df = pd.read_csv(
        OUTPUT_DIR / "q4_featured_data.csv", sep=",", header=0, encoding="utf-8"
    )

    print(f"\n{'='*70}")
    print("Q4: èˆä¼´å’Œé€‰æ‰‹ç‰¹å¾å¯¹è¯„å§”è¯„åˆ†/ç²‰ä¸æŠ•ç¥¨çš„å½±å“åˆ†æ")
    print("ï¼ˆæ§åˆ¶æ—©æœŸè¡¨ç°åçš„é™æ€ç‰¹å¾ç‹¬ç«‹è´¡çŒ®ï¼‰")
    print(f"{'='*70}")
    print(f"åŸå§‹æ•°æ®: {df.shape[0]} æ ·æœ¬ Ã— {df.shape[1]} ç‰¹å¾")

    # ==================== è®¡ç®—å› å˜é‡ ====================
    print(f"\nè®¡ç®—å› å˜é‡...")

    # 1. è¯„å§”å¾—åˆ†å‡å€¼
    score_cols = [col for col in df.columns if "score_sum" in col]
    df["judge_score_mean"] = df[score_cols].mean(axis=1, skipna=True)
    print(f"  è¯„å§”å¾—åˆ†å‡å€¼: judge_score_mean (æ¥è‡ª {len(score_cols)} å‘¨æ•°æ®)")

    # 2. è§‚ä¼—æŠ•ç¥¨å‡å€¼
    audience_cols = [
        col
        for col in df.columns
        if "audience_votes" in col and col != "total_audience_votes"
    ]
    df["audience_votes_mean"] = df[audience_cols].mean(axis=1, skipna=True)
    print(f"  è§‚ä¼—æŠ•ç¥¨å‡å€¼: audience_votes_mean (æ¥è‡ª {len(audience_cols)} å‘¨æ•°æ®)")

    # 3. å°†å‡å€¼è½¬æ¢ä¸ºç›¸å¯¹æ’åï¼ˆç™¾åˆ†æ¯”å½¢å¼ï¼Œè¶Šé«˜è¶Šå¥½ï¼‰
    # æŒ‰seasonåˆ†ç»„è®¡ç®—æ’åç™¾åˆ†æ¯”ï¼ˆåŒä¸€èµ›å­£å†…æ¯”è¾ƒï¼‰
    df["judge_score_rank_pct"] = df.groupby("season")["judge_score_mean"].rank(pct=True)
    df["audience_votes_rank_pct"] = df.groupby("season")["audience_votes_mean"].rank(
        pct=True
    )

    print(f"  è¯„å§”å¾—åˆ†æ’åç™¾åˆ†æ¯”: judge_score_rank_pct")
    print(f"  è§‚ä¼—æŠ•ç¥¨æ’åç™¾åˆ†æ¯”: audience_votes_rank_pct")

    # ==================== å‡†å¤‡è‡ªå˜é‡ ====================
    print(f"\nå‡†å¤‡è‡ªå˜é‡...")

    # é™æ€ç‰¹å¾åˆ—è¡¨
    static_features = [
        "ballroom_partner",  # èˆä¼´
        "celebrity_industry",  # è¡Œä¸š
        "celebrity_homestate",  # å®¶ä¹¡
        "celebrity_age_during_season",  # å¹´é¾„
        "gender",  # æ€§åˆ«
        "is_from_usa",  # æ˜¯å¦ç¾å›½äºº
        "ballroom_partner_count",  # èˆä¼´å‚èµ›æ¬¡æ•°
        "is_legacy_season",  # æ˜¯å¦ç»å…¸èµ›å­£
        "season_total_contestants",  # å½“å­£é€‰æ‰‹æ€»æ•°
    ]

    # ç¬¬ä¸€å‘¨å’Œç¬¬äºŒå‘¨çš„è¡¨ç°ç‰¹å¾
    week_features = [
        # ç¬¬ä¸€å‘¨
        "week1_judge_rank",
        "week1_audience_rank",
        "week1_combined_rank",
        "week1_judge_pct",
        "week1_audience_pct",
        "week1_combined_pct",
        # ç¬¬äºŒå‘¨
        "week2_judge_rank",
        "week2_audience_rank",
        "week2_combined_rank",
        "week2_judge_pct",
        "week2_audience_pct",
        "week2_combined_pct",
    ]

    # ç±»åˆ«ç¼–ç 
    obj_cols = ["ballroom_partner", "celebrity_homestate", "celebrity_industry"]
    df[obj_cols] = df[obj_cols].astype("string")

    label_encoders = {}
    for col in obj_cols:
        if col in df.columns:
            le = LabelEncoder()
            df[col] = le.fit_transform(df[col].fillna("Unknown"))
            label_encoders[col] = le

    # æ„å»ºå®Œæ•´ç‰¹å¾çŸ©é˜µï¼ˆé™æ€ + ç¬¬ä¸€å‘¨&ç¬¬äºŒå‘¨è¡¨ç°ï¼‰
    all_features = static_features + week_features
    X = df[all_features].copy()

    # å› å˜é‡
    y_judge = df["judge_score_rank_pct"]  # è¯„å§”è¯„åˆ†æ’åç™¾åˆ†æ¯”
    y_audience = df["audience_votes_rank_pct"]  # è§‚ä¼—æŠ•ç¥¨æ’åç™¾åˆ†æ¯”

    print(f"\nè‡ªå˜é‡æ„æˆ:")
    print(f"  é™æ€ç‰¹å¾ ({len(static_features)} ä¸ª):")
    for feat in static_features:
        print(f"    - {feat}")
    print(f"  ç¬¬ä¸€å‘¨&ç¬¬äºŒå‘¨è¡¨ç°ç‰¹å¾ ({len(week_features)} ä¸ª):")
    for feat in week_features:
        print(f"    - {feat}")
    print(f"\nå› å˜é‡:")
    print(f"  - æ¨¡å‹1: judge_score_rank_pct (è¯„å§”è¯„åˆ†æ’åç™¾åˆ†æ¯”)")
    print(f"  - æ¨¡å‹2: audience_votes_rank_pct (è§‚ä¼—æŠ•ç¥¨æ’åç™¾åˆ†æ¯”)")

    # ç§»é™¤åŒ…å«NaNçš„è¡Œ
    valid_mask = X.notna().all(axis=1) & y_judge.notna() & y_audience.notna()
    X_clean = X[valid_mask]
    y_judge_clean = y_judge[valid_mask]
    y_audience_clean = y_audience[valid_mask]

    print(f"\næ•°æ®æ¸…æ´—å: {len(X_clean)} æ ·æœ¬ Ã— {len(all_features)} ç‰¹å¾")
    print(f"  - é™æ€ç‰¹å¾: {len(static_features)} ä¸ª")
    print(f"  - å‘¨è¡¨ç°ç‰¹å¾: {len(week_features)} ä¸ª")

    # ä¿å­˜æ ‡ç­¾ç¼–ç å™¨
    encoders_path = output_dir / "label_encoders.pkl"
    joblib.dump(label_encoders, encoders_path)
    print(f"âœ“ æ ‡ç­¾ç¼–ç å™¨å·²ä¿å­˜åˆ°: {encoders_path}")

    # ==================== è®­ç»ƒä¸¤ä¸ªæ¨¡å‹ ====================
    print(f"\n" + "=" * 70)
    print("è®­ç»ƒæ¨¡å‹1: é¢„æµ‹è¯„å§”è¯„åˆ†ï¼ˆé™æ€ç‰¹å¾+ç¬¬1-2å‘¨è¡¨ç°ï¼‰")
    judge_model, judge_results = rf_train(
        X_clean, y_judge_clean, "judge_score", output_dir
    )

    print(f"\n" + "=" * 70)
    print("è®­ç»ƒæ¨¡å‹2: é¢„æµ‹è§‚ä¼—æŠ•ç¥¨ï¼ˆé™æ€ç‰¹å¾+ç¬¬1-2å‘¨è¡¨ç°ï¼‰")
    audience_model, audience_results = rf_train(
        X_clean, y_audience_clean, "audience_votes", output_dir
    )

    # ==================== å¯¹æ¯”åˆ†æ ====================
    print(f"\n{'='*70}")
    print("æ¨¡å‹æ€§èƒ½å¯¹æ¯”ï¼ˆé™æ€ç‰¹å¾+ç¬¬1-2å‘¨è¡¨ç°ï¼‰")
    print(f"{'='*70}")

    print(f"\nè¯„å§”è¯„åˆ†æ¨¡å‹ ({judge_results['n_features']} features):")
    print(f"  æµ‹è¯•é›† RÂ²:   {judge_results['test_r2']:.4f}")
    print(
        f"  10æŠ˜CV RÂ²:   {judge_results['cv10_test_r2_mean']:.4f} Â± {judge_results['cv10_test_r2_std']:.4f}"
    )
    print(f"  è¿‡æ‹Ÿåˆå·®è·:  {judge_results['overfit_gap']:.4f}")

    print(f"\nè§‚ä¼—æŠ•ç¥¨æ¨¡å‹ ({audience_results['n_features']} features):")
    print(f"  æµ‹è¯•é›† RÂ²:   {audience_results['test_r2']:.4f}")
    print(
        f"  10æŠ˜CV RÂ²:   {audience_results['cv10_test_r2_mean']:.4f} Â± {audience_results['cv10_test_r2_std']:.4f}"
    )
    print(f"  è¿‡æ‹Ÿåˆå·®è·:  {audience_results['overfit_gap']:.4f}")

    # ==================== ç‰¹å¾é‡è¦æ€§å¯¹æ¯”ä¸åˆ†æ ====================
    print(f"\n{'='*70}")
    print("ç‰¹å¾é‡è¦æ€§è¯¦ç»†åˆ†æ")
    print(f"{'='*70}")

    # è¯»å–ä¸¤ä¸ªæ¨¡å‹çš„ç‰¹å¾é‡è¦æ€§
    judge_importance = pd.read_csv(output_dir / "feature_importance_judge_score.csv")
    audience_importance = pd.read_csv(
        output_dir / "feature_importance_audience_votes.csv"
    )

    # æ ‡è®°ç‰¹å¾ç±»å‹
    judge_importance["feature_type"] = judge_importance["feature"].apply(
        lambda x: "é™æ€ç‰¹å¾" if x in static_features else "å‘¨è¡¨ç°"
    )
    audience_importance["feature_type"] = audience_importance["feature"].apply(
        lambda x: "é™æ€ç‰¹å¾" if x in static_features else "å‘¨è¡¨ç°"
    )

    # è®¡ç®—å„ç±»ç‰¹å¾çš„ç´¯ç§¯é‡è¦æ€§
    print(f"\nã€è¯„å§”è¯„åˆ†æ¨¡å‹ã€‘ç‰¹å¾é‡è¦æ€§åˆ†ç»„ç»Ÿè®¡:")
    judge_static_sum = judge_importance[judge_importance["feature_type"] == "é™æ€ç‰¹å¾"][
        "importance"
    ].sum()
    judge_week_sum = judge_importance[judge_importance["feature_type"] == "å‘¨è¡¨ç°"][
        "importance"
    ].sum()
    print(f"  é™æ€ç‰¹å¾ç´¯ç§¯é‡è¦æ€§: {judge_static_sum:.4f} ({judge_static_sum*100:.2f}%)")
    print(f"  å‘¨è¡¨ç°ç‰¹å¾ç´¯ç§¯é‡è¦æ€§: {judge_week_sum:.4f} ({judge_week_sum*100:.2f}%)")

    print(f"\n  é™æ€ç‰¹å¾ Top 5:")
    for _, row in (
        judge_importance[judge_importance["feature_type"] == "é™æ€ç‰¹å¾"]
        .head(5)
        .iterrows()
    ):
        print(f"    {row['feature']:<35}: {row['importance']:.4f}")

    print(f"\n  å‘¨è¡¨ç°ç‰¹å¾ Top 5:")
    for _, row in (
        judge_importance[judge_importance["feature_type"] == "å‘¨è¡¨ç°"]
        .head(5)
        .iterrows()
    ):
        print(f"    {row['feature']:<35}: {row['importance']:.4f}")

    print(f"\nã€è§‚ä¼—æŠ•ç¥¨æ¨¡å‹ã€‘ç‰¹å¾é‡è¦æ€§åˆ†ç»„ç»Ÿè®¡:")
    audience_static_sum = audience_importance[
        audience_importance["feature_type"] == "é™æ€ç‰¹å¾"
    ]["importance"].sum()
    audience_week_sum = audience_importance[
        audience_importance["feature_type"] == "å‘¨è¡¨ç°"
    ]["importance"].sum()
    print(
        f"  é™æ€ç‰¹å¾ç´¯ç§¯é‡è¦æ€§: {audience_static_sum:.4f} ({audience_static_sum*100:.2f}%)"
    )
    print(
        f"  å‘¨è¡¨ç°ç‰¹å¾ç´¯ç§¯é‡è¦æ€§: {audience_week_sum:.4f} ({audience_week_sum*100:.2f}%)"
    )

    print(f"\n  é™æ€ç‰¹å¾ Top 5:")
    for _, row in (
        audience_importance[audience_importance["feature_type"] == "é™æ€ç‰¹å¾"]
        .head(5)
        .iterrows()
    ):
        print(f"    {row['feature']:<35}: {row['importance']:.4f}")

    print(f"\n  å‘¨è¡¨ç°ç‰¹å¾ Top 5:")
    for _, row in (
        audience_importance[audience_importance["feature_type"] == "å‘¨è¡¨ç°"]
        .head(5)
        .iterrows()
    ):
        print(f"    {row['feature']:<35}: {row['importance']:.4f}")

    # åˆå¹¶å¯¹æ¯”ï¼ˆåªçœ‹é™æ€ç‰¹å¾ï¼‰
    print(f"\n{'='*70}")
    print("é™æ€ç‰¹å¾å¯¹è¯„å§”/ç²‰ä¸å½±å“å¯¹æ¯”ï¼ˆæ’é™¤å‘¨è¡¨ç°å½±å“åï¼‰")
    print(f"{'='*70}")

    judge_static = judge_importance[judge_importance["feature_type"] == "é™æ€ç‰¹å¾"][
        ["feature", "importance"]
    ].copy()
    judge_static.columns = ["feature", "importance_judge"]

    audience_static = audience_importance[
        audience_importance["feature_type"] == "é™æ€ç‰¹å¾"
    ][["feature", "importance"]].copy()
    audience_static.columns = ["feature", "importance_audience"]

    comparison = judge_static.merge(audience_static, on="feature")
    comparison["diff"] = (
        comparison["importance_judge"] - comparison["importance_audience"]
    )
    comparison["abs_diff"] = abs(comparison["diff"])
    comparison = comparison.sort_values("abs_diff", ascending=False)

    print(f"\né™æ€ç‰¹å¾å¯¹è¯„å§”å’Œç²‰ä¸å½±å“çš„å·®å¼‚æ’åº:")
    print(f"{'ç‰¹å¾':<35} {'è¯„å§”é‡è¦æ€§':>12} {'ç²‰ä¸é‡è¦æ€§':>12} {'å·®å¼‚':>10}")
    print("-" * 70)
    for _, row in comparison.iterrows():
        direction = "â†’è¯„å§”" if row["diff"] > 0 else "â†’ç²‰ä¸"
        print(
            f"{row['feature']:<35} {row['importance_judge']:>12.4f} {row['importance_audience']:>12.4f} {row['diff']:>+10.4f} {direction}"
        )

    # ä¿å­˜å¯¹æ¯”ç»“æœï¼ˆåŒ…å«æ‰€æœ‰ç‰¹å¾ï¼‰
    all_comparison = judge_importance.merge(
        audience_importance, on="feature", suffixes=("_judge", "_audience")
    )
    all_comparison["diff"] = (
        all_comparison["importance_judge"] - all_comparison["importance_audience"]
    )
    all_comparison_path = output_dir / "feature_importance_comparison.csv"
    all_comparison.to_csv(all_comparison_path, index=False, encoding="utf-8")
    print(f"\nâœ“ å®Œæ•´ç‰¹å¾é‡è¦æ€§å¯¹æ¯”å·²ä¿å­˜åˆ°: {all_comparison_path}")

    # ä¿å­˜é™æ€ç‰¹å¾å¯¹æ¯”
    static_comparison_path = output_dir / "feature_importance_static_only.csv"
    comparison.to_csv(static_comparison_path, index=False, encoding="utf-8")
    print(f"âœ“ é™æ€ç‰¹å¾é‡è¦æ€§å¯¹æ¯”å·²ä¿å­˜åˆ°: {static_comparison_path}")

    print(f"\n{'='*70}")
    print("æ ¸å¿ƒç»“è®º")
    print(f"{'='*70}")

    # æ‰¾å‡ºå¯¹è¯„å§”å½±å“æ›´å¤§çš„é™æ€ç‰¹å¾
    judge_dominated = comparison[comparison["diff"] > 0.01]["feature"].tolist()
    audience_dominated = comparison[comparison["diff"] < -0.01]["feature"].tolist()

    print(f"\n1. æ¨¡å‹æ•´ä½“è¡¨ç°:")
    print(f"   è¯„å§”è¯„åˆ†æ¨¡å‹ RÂ² = {judge_results['test_r2']:.4f}")
    print(f"   è§‚ä¼—æŠ•ç¥¨æ¨¡å‹ RÂ² = {audience_results['test_r2']:.4f}")

    print(f"\n2. ç‰¹å¾ç±»å‹è´¡çŒ®åº¦:")
    print(
        f"   ã€è¯„å§”è¯„åˆ†ã€‘é™æ€ç‰¹å¾è´¡çŒ®: {judge_static_sum*100:.2f}%, å‘¨è¡¨ç°è´¡çŒ®: {judge_week_sum*100:.2f}%"
    )
    print(
        f"   ã€è§‚ä¼—æŠ•ç¥¨ã€‘é™æ€ç‰¹å¾è´¡çŒ®: {audience_static_sum*100:.2f}%, å‘¨è¡¨ç°è´¡çŒ®: {audience_week_sum*100:.2f}%"
    )

    if judge_static_sum < 0.2 and audience_static_sum < 0.2:
        print(f"\n   ğŸ’¡ å…³é”®å‘ç°: åœ¨æ§åˆ¶æ—©æœŸè¡¨ç°åï¼Œé™æ€ç‰¹å¾ï¼ˆèˆä¼´ã€å¹´é¾„ã€èŒä¸šç­‰ï¼‰")
        print(f"      å¯¹è¯„å§”è¯„åˆ†å’Œç²‰ä¸æŠ•ç¥¨çš„å½±å“éƒ½å¾ˆå°ï¼ˆ<20%ï¼‰ï¼Œè¯´æ˜ï¼š")
        print(f"      - è¯„å§”ä¸»è¦çœ‹èˆè¹ˆæŠ€å·§å’Œè¡¨ç°ï¼Œä¸å¤ªå—é€‰æ‰‹èƒŒæ™¯å½±å“")
        print(f"      - ç²‰ä¸ä¸»è¦çœ‹å®é™…è¡¨æ¼”ï¼Œä¸å¤ªå—é™æ€èº«ä»½å½±å“")

    print(f"\n3. å¯¹è¯„å§”è¯„åˆ†å½±å“æ›´å¤§çš„é™æ€ç‰¹å¾:")
    if judge_dominated:
        for feat in judge_dominated:
            print(f"   - {feat}")
    else:
        print(f"   (æ— æ˜¾è‘—å·®å¼‚)")

    print(f"\n4. å¯¹ç²‰ä¸æŠ•ç¥¨å½±å“æ›´å¤§çš„é™æ€ç‰¹å¾:")
    if audience_dominated:
        for feat in audience_dominated:
            print(f"   - {feat}")
    else:
        print(f"   (æ— æ˜¾è‘—å·®å¼‚)")

    print(f"\n5. ç­”é¢˜å»ºè®®:")
    print(f"   - èˆä¼´å’Œé€‰æ‰‹ç‰¹å¾å¯¹æ¯”èµ›ç»“æœæœ‰å½±å“ï¼Œä½†**ä¸æ˜¯ä¸»å¯¼å› ç´ **")
    print(
        f"   - å®é™…è¡¨ç°ï¼ˆæ—©æœŸæ’åï¼‰æ‰æ˜¯ä¸»å¯¼å› ç´ ï¼ˆå {max(judge_week_sum, audience_week_sum)*100:.0f}%+ï¼‰"
    )
    print(f"   - è¯„å§”å’Œç²‰ä¸å¯¹é™æ€ç‰¹å¾çš„ååº”æ¨¡å¼åŸºæœ¬ä¸€è‡´")

    # ä¿å­˜ç»“æœæ‘˜è¦
    results_summary = {
        "judge_score_model": judge_results,
        "audience_votes_model": audience_results,
        "static_features_contribution": {
            "judge_model": float(judge_static_sum),
            "audience_model": float(audience_static_sum),
        },
        "week_features_contribution": {
            "judge_model": float(judge_week_sum),
            "audience_model": float(audience_week_sum),
        },
        "static_features_comparison": comparison.to_dict("records"),
    }

    import json

    results_path = output_dir / "rf_training_results.json"
    with open(results_path, "w", encoding="utf-8") as f:
        json.dump(results_summary, f, indent=2, ensure_ascii=False)

    print(f"\nâœ“ è®­ç»ƒç»“æœå·²ä¿å­˜åˆ°: {results_path}")
    print("=" * 70)


if __name__ == "__main__":
    main()
